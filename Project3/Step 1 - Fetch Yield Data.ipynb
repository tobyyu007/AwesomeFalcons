{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d62abd29",
   "metadata": {},
   "source": [
    "## <span style=color:blue>This notebook is fetching soybean yields for an ML pipeline </spann>\n",
    "\n",
    "<span style=color:blue>It pulls from USDA NASS.</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "748db334",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This useful if I want to give unique names to directories or files\n",
    "import datetime\n",
    "def curr_timestamp():\n",
    "    current_datetime = datetime.datetime.now()\n",
    "    formatted_datetime = current_datetime.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    return formatted_datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081bcb69",
   "metadata": {},
   "source": [
    "### <span style=color:blue> Accessing USDA NASS, following code from https://towardsdatascience.com/harvest-and-analyze-agricultural-data-with-the-usda-nass-api-python-and-tableau-a6af374b8138.  In first cell below we define a class for interacting with the NASS QuickStats API, and in second cell we illustrate how to invoke that class </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ec026614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://towardsdatascience.com/harvest-and-analyze-agricultural-data-with-the-usda-nass-api-python-and-tableau-a6af374b8138\n",
    "# with edits\n",
    "\n",
    "#   Name:           c_usda_quick_stats.py\n",
    "#   Author:         Randy Runtsch\n",
    "#   Date:           March 29, 2022\n",
    "#   Project:        Query USDA QuickStats API\n",
    "#   Author:         Randall P. Runtsch\n",
    "#\n",
    "#   Description:    Query the USDA QuickStats api_GET API with a specified set of \n",
    "#                   parameters. Write the retrieved data, in CSV format, to a file.\n",
    "#\n",
    "#   See Quick Stats (NASS) API user guide:  https://quickstats.nass.usda.gov/api\n",
    "#   Request a QuickStats API key here:      https://quickstats.nass.usda.gov/api#param_define\n",
    "#\n",
    "#   Attribution: This product uses the NASS API but is not endorsed or certified by NASS.\n",
    "#\n",
    "#   Changes\n",
    "#\n",
    "\n",
    "import urllib.request\n",
    "from urllib.error import HTTPError\n",
    "from requests.utils import requote_uri\n",
    "import requests\n",
    "\n",
    "# Retrieve NASS API key from environment variables (you have to get your own)\n",
    "import os\n",
    "my_NASS_API_key = os.getenv('NASS_API_KEY')\n",
    "\n",
    "class c_usda_quick_stats:\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        # Set the USDA QuickStats API key, API base URL, and output file path where CSV files will be written. \n",
    "\n",
    "        # self.api_key = 'PASTE_YOUR_API_KEY_HERE'\n",
    "        self.api_key = \"62A21C68-28D5-3C34-B09F-1E68D569ABE3\"\n",
    "\n",
    "        self.base_url_api_get = 'http://quickstats.nass.usda.gov/api/api_GET/?key=' \\\n",
    "                                + self.api_key + '&'\n",
    "\n",
    "    def get_data(self, parameters, file_path, file_name):\n",
    "\n",
    "        # Call the api_GET api with the specified parameters. \n",
    "        # Write the CSV data to the specified output file.\n",
    "\n",
    "        # Create the full URL and retrieve the data from the Quick Stats server.\n",
    "        \n",
    "        full_url = self.base_url_api_get + parameters        \n",
    "        print(full_url)\n",
    "\n",
    "        try:\n",
    "            s_result = urllib.request.urlopen(full_url)\n",
    "            # print(type(s_result))\n",
    "            print(s_result.status, s_result.reason)\n",
    "            # print(s_result.status_code)\n",
    "            s_text = s_result.read().decode('utf-8')\n",
    "\n",
    "            # Create the output file and write the CSV data records to the file.\n",
    "\n",
    "            s_file_name = file_path + file_name\n",
    "            o_file = open(s_file_name, \"w\", encoding=\"utf8\")\n",
    "            o_file.write(s_text)\n",
    "            o_file.close()\n",
    "        except HTTPError as error:\n",
    "            print(error.code, error.reason)\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"An error occurred while fetching the data: {e}\")\n",
    "        except ValueError as e:\n",
    "            print(f\"Failed to parse the response data: {e}\")\n",
    "        except:\n",
    "            print(f\"Failed because of unknown exception; perhaps the USDA NASS site is down\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194bf18e",
   "metadata": {},
   "source": [
    "<span style=color:blue>Now a query that fetches useful soybean yield data.  I am focused on the top 7 soy-producing states in the US, and on the years 2003 to 2022.   </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6510e506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://quickstats.nass.usda.gov/api/api_GET/?key=62A21C68-28D5-3C34-B09F-1E68D569ABE3&source_desc=SURVEY&sector_desc=CROPS&group_desc%3DFIELD%20CROPS&commodity_desc=Wheat&statisticcat_desc=YIELD&geographic_level=STATE&agg_level_desc=COUNTY&state_ansi=53&state_ansi=30&state_ansi=38&state_ansi=46&state_ansi=20&state_ansi=40&state_ansi=48&year__GE=2000&year__LE=2023&format=CSV\n",
      "200 OK\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import urllib.parse\n",
    "\n",
    "output_dir = './yield_data/'\n",
    "\n",
    "# Create a string with search parameters, then create an instance of\n",
    "# the c_usda_quick_stats class and use that to fetch data from QuickStats\n",
    "# and write it to a file\n",
    "\n",
    "# It took a while to get the parameter names just right...\n",
    "#   The parameters names are listed in\n",
    "#      https://quickstats.nass.usda.gov/param_define\n",
    "#   (some additional resources in https://quickstats.nass.usda.gov/tutorials)\n",
    "#   Also, look at the column names that show up in the csv files that you get back\n",
    "parameters =    'source_desc=SURVEY' +  \\\n",
    "                '&sector_desc=CROPS' + \\\n",
    "                '&' + urllib.parse.quote('group_desc=FIELD CROPS') + \\\n",
    "                '&commodity_desc=Wheat' + \\\n",
    "                '&statisticcat_desc=YIELD' + \\\n",
    "                '&geographic_level=STATE' + \\\n",
    "                '&agg_level_desc=COUNTY' + \\\n",
    "                '&state_ansi=53' + \\\n",
    "                '&state_ansi=30' + \\\n",
    "                '&state_ansi=38' + \\\n",
    "                '&state_ansi=46' + \\\n",
    "                '&state_ansi=20' + \\\n",
    "                '&state_ansi=40' + \\\n",
    "                '&state_ansi=48' + \\\n",
    "                '&year__GE=2000' + \\\n",
    "                '&year__LE=2023' + \\\n",
    "                '&format=CSV'\n",
    "\n",
    "stats = c_usda_quick_stats()\n",
    "\n",
    "# holding this timestamp; we may used it to import the created csv file\n",
    "latest_curr_timestamp = curr_timestamp()\n",
    "filename = 'wheat_yield_data__' + latest_curr_timestamp + '.csv'\n",
    "\n",
    "# Including curr_timestamp() into file name to keep outputs separated during development/exploration\n",
    "stats.get_data(parameters, output_dir, filename)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c890336",
   "metadata": {},
   "source": [
    "### <span style=color:blue>After inspecting the output we see that there is double counting.  In particular, see the columns for \"short_desc\".  So, we will drop all records with short_desc != \"SOYBEANS - YIELD, MEASURED IN BU / ACRE\"</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dec3aa1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              short_desc\n",
      "0                   WHEAT - YIELD, MEASURED IN BU / ACRE\n",
      "4189    WHEAT - YIELD, MEASURED IN BU / NET PLANTED ACRE\n",
      "5466        WHEAT - YIELD, MEASURED IN BU / PLANTED ACRE\n",
      "5601     WHEAT, IRRIGATED - YIELD, MEASURED IN BU / ACRE\n",
      "7011   WHEAT, IRRIGATED - YIELD, MEASURED IN BU / NET...\n",
      "7425   WHEAT, IRRIGATED - YIELD, MEASURED IN BU / PLA...\n",
      "7447   WHEAT, NON-IRRIGATED - YIELD, MEASURED IN BU /...\n",
      "10525  WHEAT, NON-IRRIGATED - YIELD, MEASURED IN BU /...\n",
      "11641  WHEAT, NON-IRRIGATED - YIELD, MEASURED IN BU /...\n",
      "11718  WHEAT, NON-IRRIGATED, CONTINUOUS CROP - YIELD,...\n",
      "\n",
      "4189\n",
      "\n",
      "3988\n",
      "\n",
      "557\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "output_dir = './yield_data/'\n",
    "\n",
    "df = pd.read_csv(output_dir + filename)\n",
    "# print(df.head())\n",
    "\n",
    "df1 = df[['short_desc']].drop_duplicates()\n",
    "print(df1.head(10))\n",
    "print()\n",
    "\n",
    "# keep only records about full yield\n",
    "df = df[df['short_desc'] == \"WHEAT - YIELD, MEASURED IN BU / ACRE\"]\n",
    "print(len(df))\n",
    "# 10295\n",
    "\n",
    "print()\n",
    "\n",
    "# found some bad_county_names by visual inspection of the csv\n",
    "bad_county_names = ['OTHER COUNTIES', 'OTHER (COMBINED) COUNTIES']\n",
    "df = df[~df.county_name.isin(bad_county_names)]\n",
    "\n",
    "print(len(df))\n",
    "# 9952\n",
    "\n",
    "print()\n",
    "\n",
    "df2 = df[['state_name','county_name']].drop_duplicates()\n",
    "print(len(df2))\n",
    "# 559\n",
    "\n",
    "# Note: using SQL I found that of the 559 state-county pairs total:\n",
    "#          212 state-county pairs have data for all 20 years\n",
    "#          347 state-county pairs have data for < 20 years\n",
    "#\n",
    "#          486 have year 2022\n",
    "#          418 have year 2021\n",
    "#          514 have year 2020\n",
    "# I will live with that\n",
    "\n",
    "# cleaning up a column name\n",
    "df = df.rename(columns={'Value': 'yield'})\n",
    "\n",
    "output_dir = './yield_data/'\n",
    "output_file = 'repaired_yield__' + curr_timestamp() + '.csv'\n",
    "\n",
    "df.to_csv(output_dir + output_file, index=False)\n",
    "\n",
    "# I imported this table into postgres so that I could use SQL ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0555f187",
   "metadata": {},
   "source": [
    "#### <span style=color:blue>Saving the csv I'm happy with in a designated place in my \"archives\" directory</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "020f70ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./yield data/wheat_yield_data.csv'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "output_dir = './yield_data/'\n",
    "archives_dir = './yield_data/'\n",
    "src_file = output_file # from preceding cell\n",
    "tgt_file = 'wheat_yield_data.csv'\n",
    "\n",
    "shutil.copyfile(output_dir + src_file, archives_dir + tgt_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58931598",
   "metadata": {},
   "source": [
    "#### <span style=color:blue>Projecting out the columns and records that I don't need for my ML learning table, and archiving that result, also. </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1624c582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year state_name county_name  yield\n",
      "0  2007     KANSAS    CHEYENNE   47.0\n",
      "1  2006     KANSAS    CHEYENNE   20.0\n",
      "2  2005     KANSAS    CHEYENNE   21.0\n",
      "3  2004     KANSAS    CHEYENNE   18.0\n",
      "4  2003     KANSAS    CHEYENNE   32.0\n",
      "\n",
      "3988\n",
      "Empty DataFrame\n",
      "Columns: [year, state_name, county_name, yield]\n",
      "Index: []\n",
      "\n",
      "wrote file  ./yield data/d\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "archives_dir = './yield_data/'\n",
    "tgt_file = 'wheat_yield_data.csv'\n",
    "\n",
    "df = pd.read_csv(archives_dir + tgt_file)\n",
    "# print(df.head())\n",
    "\n",
    "cols_to_keep = ['year','state_name','county_name','yield']\n",
    "dfml = df[cols_to_keep]\n",
    "\n",
    "print(dfml.head())\n",
    "print()\n",
    "print(dfml.shape[0])\n",
    "# Note: this particular df has 9952 rows\n",
    "\n",
    "# checking there are no null values for 'yield':\n",
    "print(dfml[dfml['yield'].isnull()].head())\n",
    "\n",
    "tgt_file_01 = 'd'\n",
    "dfml.to_csv(archives_dir + tgt_file_01, index=False)\n",
    "print('\\nwrote file ', archives_dir + tgt_file_01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1da869f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FoodSecurity",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
